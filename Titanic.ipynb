{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, Convolution2D, MaxPooling2D, Flatten\n",
    "from keras import optimizers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"https://storage.googleapis.com/kaggle-competitions-data/kaggle/3136/train.csv?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1553490003&Signature=P5LMsu68MuZbx8yhKhdY2MHw12lj8OUtP0MVgMmKj3nTF3zZ3SfKdf1ccb3stMCuHjSywrMpb%2BPrlWoVYgzQqCRcivTncl0oGcOssdRA3uRfcQzBAByVpCmhOCHAq%2B2oSA9vn1q0FoFrn1Tj%2Bh2TzCc8cJiwJmVdTbBRwWwYxTUNUgDweBE04AZdN3CNi1NSgCbGWlePMecNZeJg3MkJ20BI8mYTj9d06X5o8V7yeGZ7pnuizpD82LbC2R3vE7yJD9sV1yMs57g%2FpT5NnjRvdDWyO2RoFhLALLHi9GH8scjvrXF73OTdu5fLvnXF9IFuz%2FsgV3IH6QUJzyCq3VckDw%3D%3D\")\n",
    "test_data = pd.read_csv(\"https://storage.googleapis.com/kaggle-competitions-data/kaggle/3136/test.csv?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1553490001&Signature=KamEeUEMt4SqnK7p%2BfcbopZuoH7PbGzcRxJCxKUstzscCqBADiLJViPbdgrMyjJd4%2FDFhEdV11lDSCDYEqjpk8e366r0T4V1Nq%2F01ImD3OoCp9veiy1Hj3Gl8soQ0rE%2F5T3e%2BZ6gGYv2%2FTf9uL7QFqU9KBBBW3sWR%2BtHHPhfsTOwF%2BesyAO2I8PcYpLx9GKxYNo12%2Bd9A83ya8ez8YEcSaFqdIB3e43bz%2Bkdg7Gl7QyIVKpse101Pnfge5ifCdyJqiOYBwFhtKgSt4kCcoo6P2SArL89dWc%2Bi7fCOkwfqGK0wsXhprTUKuWWjqGpNKmuivs1Na6TXWFETLMdenAN9A%3D%3D\")\n",
    "test_data1 = pd.read_csv(\"https://storage.googleapis.com/kaggle-competitions-data/kaggle/3136/test.csv?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1553490001&Signature=KamEeUEMt4SqnK7p%2BfcbopZuoH7PbGzcRxJCxKUstzscCqBADiLJViPbdgrMyjJd4%2FDFhEdV11lDSCDYEqjpk8e366r0T4V1Nq%2F01ImD3OoCp9veiy1Hj3Gl8soQ0rE%2F5T3e%2BZ6gGYv2%2FTf9uL7QFqU9KBBBW3sWR%2BtHHPhfsTOwF%2BesyAO2I8PcYpLx9GKxYNo12%2Bd9A83ya8ez8YEcSaFqdIB3e43bz%2Bkdg7Gl7QyIVKpse101Pnfge5ifCdyJqiOYBwFhtKgSt4kCcoo6P2SArL89dWc%2Bi7fCOkwfqGK0wsXhprTUKuWWjqGpNKmuivs1Na6TXWFETLMdenAN9A%3D%3D\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "4            5         0       3   \n",
      "5            6         0       3   \n",
      "6            7         0       1   \n",
      "7            8         0       3   \n",
      "8            9         1       3   \n",
      "9           10         1       2   \n",
      "\n",
      "                                                Name  Sex   Age  SibSp  Parch  \\\n",
      "0                            Braund, Mr. Owen Harris    0  22.0      1      0   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...    1  38.0      1      0   \n",
      "2                             Heikkinen, Miss. Laina    1  26.0      0      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)    1  35.0      1      0   \n",
      "4                           Allen, Mr. William Henry    0  35.0      0      0   \n",
      "5                                   Moran, Mr. James    0   NaN      0      0   \n",
      "6                            McCarthy, Mr. Timothy J    0  54.0      0      0   \n",
      "7                     Palsson, Master. Gosta Leonard    0   2.0      3      1   \n",
      "8  Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)    1  27.0      0      2   \n",
      "9                Nasser, Mrs. Nicholas (Adele Achem)    1  14.0      1      0   \n",
      "\n",
      "             Ticket     Fare  Cabin Embarked  \n",
      "0         A/5 21171   7.2500      0        0  \n",
      "1          PC 17599  71.2833      1        1  \n",
      "2  STON/O2. 3101282   7.9250      0        0  \n",
      "3            113803  53.1000      1        0  \n",
      "4            373450   8.0500      0        0  \n",
      "5            330877   8.4583      0        2  \n",
      "6             17463  51.8625      1        0  \n",
      "7            349909  21.0750      0        0  \n",
      "8            347742  11.1333      0        0  \n",
      "9            237736  30.0708      0        1  \n"
     ]
    }
   ],
   "source": [
    "train_data['Sex'] = np.where(train_data['Sex']=='female', 1, 0)\n",
    "train_data['Cabin'] = (train_data['Cabin'].notnull()).astype('int')\n",
    "train_data.loc[train_data.Embarked == 'S', 'Embarked'] = 0\n",
    "train_data.loc[train_data.Embarked == 'C', 'Embarked'] = 1\n",
    "train_data.loc[train_data.Embarked =='Q', 'Embarked'] = 2\n",
    "\n",
    "\n",
    "print(train_data.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    PassengerId  Pclass                                               Name  \\\n",
      "0           892       3                                   Kelly, Mr. James   \n",
      "1           893       3                   Wilkes, Mrs. James (Ellen Needs)   \n",
      "2           894       2                          Myles, Mr. Thomas Francis   \n",
      "3           895       3                                   Wirz, Mr. Albert   \n",
      "4           896       3       Hirvonen, Mrs. Alexander (Helga E Lindqvist)   \n",
      "5           897       3                         Svensson, Mr. Johan Cervin   \n",
      "6           898       3                               Connolly, Miss. Kate   \n",
      "7           899       2                       Caldwell, Mr. Albert Francis   \n",
      "8           900       3          Abrahim, Mrs. Joseph (Sophie Halaut Easu)   \n",
      "9           901       3                            Davies, Mr. John Samuel   \n",
      "10          902       3                                   Ilieff, Mr. Ylio   \n",
      "11          903       1                         Jones, Mr. Charles Cresson   \n",
      "12          904       1      Snyder, Mrs. John Pillsbury (Nelle Stevenson)   \n",
      "13          905       2                               Howard, Mr. Benjamin   \n",
      "14          906       1  Chaffee, Mrs. Herbert Fuller (Carrie Constance...   \n",
      "\n",
      "    Sex   Age  SibSp  Parch       Ticket     Fare  Cabin  Embarked  \n",
      "0     0  34.5      0      0       330911   7.8292      0         2  \n",
      "1     1  47.0      1      0       363272   7.0000      0         0  \n",
      "2     0  62.0      0      0       240276   9.6875      0         2  \n",
      "3     0  27.0      0      0       315154   8.6625      0         0  \n",
      "4     1  22.0      1      1      3101298  12.2875      0         0  \n",
      "5     0  14.0      0      0         7538   9.2250      0         0  \n",
      "6     1  30.0      0      0       330972   7.6292      0         2  \n",
      "7     0  26.0      1      1       248738  29.0000      0         0  \n",
      "8     1  18.0      0      0         2657   7.2292      0         1  \n",
      "9     0  21.0      2      0    A/4 48871  24.1500      0         0  \n",
      "10    0   NaN      0      0       349220   7.8958      0         0  \n",
      "11    0  46.0      0      0          694  26.0000      0         0  \n",
      "12    1  23.0      1      0        21228  82.2667      1         0  \n",
      "13    0  63.0      1      0        24065  26.0000      0         0  \n",
      "14    1  47.0      1      0  W.E.P. 5734  61.1750      1         0  \n"
     ]
    }
   ],
   "source": [
    "test_data['Sex'] = np.where(test_data['Sex']=='female', 1, 0)\n",
    "test_data['Cabin'] = (test_data['Cabin'].notnull()).astype('int')\n",
    "test_data.loc[test_data.Embarked == 'S', 'Embarked'] = 0\n",
    "test_data.loc[test_data.Embarked == 'C', 'Embarked'] = 1\n",
    "test_data.loc[test_data.Embarked =='Q', 'Embarked'] = 2\n",
    "\n",
    "print(test_data.head(15))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Survived', 'Pclass', 'Age', 'Sex', 'SibSp', 'Parch', 'Fare', 'Cabin', 'Embarked']\n"
     ]
    }
   ],
   "source": [
    "sc = StandardScaler()\n",
    "\n",
    "train_data = train_data[['Survived','Pclass','Age','Sex','SibSp','Parch','Fare','Cabin','Embarked']]\n",
    "test_data = test_data[['Pclass','Age','Sex','SibSp','Parch','Fare','Cabin','Embarked']]\n",
    "\n",
    "\n",
    "print(list(train_data))\n",
    "train_data.fillna(train_data.mean(), inplace=True)\n",
    "test_data.fillna(test_data.mean(), inplace=True)\n",
    "\n",
    "X_train = train_data.iloc[:,1:9]   \n",
    "y_train = train_data.iloc[:,0]     \n",
    "\n",
    "\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.fit_transform(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=8, units=3, kernel_initializer=\"uniform\")`\n",
      "  \"\"\"\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=2, kernel_initializer=\"uniform\")`\n",
      "  import sys\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=1, kernel_initializer=\"uniform\")`\n",
      "  if __name__ == '__main__':\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/models.py:981: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "891/891 [==============================] - 2s 2ms/step - loss: 0.6900 - acc: 0.6083\n",
      "Epoch 2/100\n",
      "891/891 [==============================] - 0s 242us/step - loss: 0.6809 - acc: 0.6263\n",
      "Epoch 3/100\n",
      "891/891 [==============================] - 0s 266us/step - loss: 0.6612 - acc: 0.7587\n",
      "Epoch 4/100\n",
      "891/891 [==============================] - 0s 264us/step - loss: 0.6300 - acc: 0.7890\n",
      "Epoch 5/100\n",
      "891/891 [==============================] - 0s 262us/step - loss: 0.5988 - acc: 0.7868\n",
      "Epoch 6/100\n",
      "891/891 [==============================] - 0s 336us/step - loss: 0.5739 - acc: 0.7901\n",
      "Epoch 7/100\n",
      "891/891 [==============================] - 0s 368us/step - loss: 0.5552 - acc: 0.7912\n",
      "Epoch 8/100\n",
      "891/891 [==============================] - 0s 323us/step - loss: 0.5399 - acc: 0.7957\n",
      "Epoch 9/100\n",
      "891/891 [==============================] - 0s 352us/step - loss: 0.5266 - acc: 0.8013\n",
      "Epoch 10/100\n",
      "891/891 [==============================] - 0s 332us/step - loss: 0.5155 - acc: 0.7991\n",
      "Epoch 11/100\n",
      "891/891 [==============================] - 0s 322us/step - loss: 0.5056 - acc: 0.8047\n",
      "Epoch 12/100\n",
      "891/891 [==============================] - 0s 265us/step - loss: 0.4971 - acc: 0.8092\n",
      "Epoch 13/100\n",
      "891/891 [==============================] - 0s 248us/step - loss: 0.4895 - acc: 0.8103\n",
      "Epoch 14/100\n",
      "891/891 [==============================] - 0s 290us/step - loss: 0.4823 - acc: 0.8137\n",
      "Epoch 15/100\n",
      "891/891 [==============================] - 0s 316us/step - loss: 0.4765 - acc: 0.8114\n",
      "Epoch 16/100\n",
      "891/891 [==============================] - 0s 272us/step - loss: 0.4719 - acc: 0.8182\n",
      "Epoch 17/100\n",
      "891/891 [==============================] - 0s 241us/step - loss: 0.4672 - acc: 0.8103\n",
      "Epoch 18/100\n",
      "891/891 [==============================] - 0s 251us/step - loss: 0.4625 - acc: 0.8182\n",
      "Epoch 19/100\n",
      "891/891 [==============================] - 0s 244us/step - loss: 0.4584 - acc: 0.8204\n",
      "Epoch 20/100\n",
      "891/891 [==============================] - 0s 254us/step - loss: 0.4563 - acc: 0.8182\n",
      "Epoch 21/100\n",
      "891/891 [==============================] - 0s 232us/step - loss: 0.4520 - acc: 0.8193\n",
      "Epoch 22/100\n",
      "891/891 [==============================] - 0s 273us/step - loss: 0.4496 - acc: 0.8182\n",
      "Epoch 23/100\n",
      "891/891 [==============================] - 0s 227us/step - loss: 0.4470 - acc: 0.8159\n",
      "Epoch 24/100\n",
      "891/891 [==============================] - 0s 231us/step - loss: 0.4446 - acc: 0.8193\n",
      "Epoch 25/100\n",
      "891/891 [==============================] - 0s 240us/step - loss: 0.4426 - acc: 0.8171\n",
      "Epoch 26/100\n",
      "891/891 [==============================] - 0s 233us/step - loss: 0.4405 - acc: 0.8193\n",
      "Epoch 27/100\n",
      "891/891 [==============================] - 0s 226us/step - loss: 0.4387 - acc: 0.8227\n",
      "Epoch 28/100\n",
      "891/891 [==============================] - 0s 228us/step - loss: 0.4372 - acc: 0.8215\n",
      "Epoch 29/100\n",
      "891/891 [==============================] - 0s 239us/step - loss: 0.4358 - acc: 0.8193\n",
      "Epoch 30/100\n",
      "891/891 [==============================] - 0s 229us/step - loss: 0.4347 - acc: 0.8227\n",
      "Epoch 31/100\n",
      "891/891 [==============================] - 0s 227us/step - loss: 0.4341 - acc: 0.8215\n",
      "Epoch 32/100\n",
      "891/891 [==============================] - 0s 230us/step - loss: 0.4326 - acc: 0.8238\n",
      "Epoch 33/100\n",
      "891/891 [==============================] - 0s 237us/step - loss: 0.4313 - acc: 0.8215\n",
      "Epoch 34/100\n",
      "891/891 [==============================] - 0s 234us/step - loss: 0.4306 - acc: 0.8227\n",
      "Epoch 35/100\n",
      "891/891 [==============================] - 0s 277us/step - loss: 0.4299 - acc: 0.8215\n",
      "Epoch 36/100\n",
      "891/891 [==============================] - 0s 291us/step - loss: 0.4292 - acc: 0.8193\n",
      "Epoch 37/100\n",
      "891/891 [==============================] - 0s 240us/step - loss: 0.4281 - acc: 0.8227\n",
      "Epoch 38/100\n",
      "891/891 [==============================] - 0s 243us/step - loss: 0.4274 - acc: 0.8249\n",
      "Epoch 39/100\n",
      "891/891 [==============================] - 0s 276us/step - loss: 0.4273 - acc: 0.8215\n",
      "Epoch 40/100\n",
      "891/891 [==============================] - 0s 258us/step - loss: 0.4265 - acc: 0.8227\n",
      "Epoch 41/100\n",
      "891/891 [==============================] - 0s 223us/step - loss: 0.4260 - acc: 0.8260\n",
      "Epoch 42/100\n",
      "891/891 [==============================] - 0s 293us/step - loss: 0.4256 - acc: 0.8260\n",
      "Epoch 43/100\n",
      "891/891 [==============================] - 0s 328us/step - loss: 0.4248 - acc: 0.8283\n",
      "Epoch 44/100\n",
      "891/891 [==============================] - 0s 279us/step - loss: 0.4243 - acc: 0.8283\n",
      "Epoch 45/100\n",
      "891/891 [==============================] - 0s 287us/step - loss: 0.4235 - acc: 0.8215\n",
      "Epoch 46/100\n",
      "891/891 [==============================] - 0s 216us/step - loss: 0.4235 - acc: 0.8238\n",
      "Epoch 47/100\n",
      "891/891 [==============================] - 0s 256us/step - loss: 0.4231 - acc: 0.8249\n",
      "Epoch 48/100\n",
      "891/891 [==============================] - 0s 286us/step - loss: 0.4223 - acc: 0.8260\n",
      "Epoch 49/100\n",
      "891/891 [==============================] - 0s 288us/step - loss: 0.4219 - acc: 0.8260\n",
      "Epoch 50/100\n",
      "891/891 [==============================] - 0s 290us/step - loss: 0.4212 - acc: 0.8249\n",
      "Epoch 51/100\n",
      "891/891 [==============================] - 0s 281us/step - loss: 0.4209 - acc: 0.8249\n",
      "Epoch 52/100\n",
      "891/891 [==============================] - 0s 331us/step - loss: 0.4205 - acc: 0.8260\n",
      "Epoch 53/100\n",
      "891/891 [==============================] - 0s 385us/step - loss: 0.4202 - acc: 0.8249\n",
      "Epoch 54/100\n",
      "891/891 [==============================] - 0s 398us/step - loss: 0.4203 - acc: 0.8272\n",
      "Epoch 55/100\n",
      "891/891 [==============================] - 0s 339us/step - loss: 0.4192 - acc: 0.8272\n",
      "Epoch 56/100\n",
      "891/891 [==============================] - 0s 484us/step - loss: 0.4200 - acc: 0.8272\n",
      "Epoch 57/100\n",
      "891/891 [==============================] - 0s 407us/step - loss: 0.4191 - acc: 0.8238\n",
      "Epoch 58/100\n",
      "891/891 [==============================] - 0s 427us/step - loss: 0.4185 - acc: 0.8272\n",
      "Epoch 59/100\n",
      "891/891 [==============================] - 0s 413us/step - loss: 0.4189 - acc: 0.8260\n",
      "Epoch 60/100\n",
      "891/891 [==============================] - 0s 337us/step - loss: 0.4179 - acc: 0.8249\n",
      "Epoch 61/100\n",
      "891/891 [==============================] - 0s 489us/step - loss: 0.4181 - acc: 0.8260\n",
      "Epoch 62/100\n",
      "891/891 [==============================] - 0s 456us/step - loss: 0.4172 - acc: 0.8260\n",
      "Epoch 63/100\n",
      "891/891 [==============================] - 0s 298us/step - loss: 0.4172 - acc: 0.8260\n",
      "Epoch 64/100\n",
      "891/891 [==============================] - 0s 393us/step - loss: 0.4174 - acc: 0.8272\n",
      "Epoch 65/100\n",
      "891/891 [==============================] - 0s 340us/step - loss: 0.4175 - acc: 0.8272\n",
      "Epoch 66/100\n",
      "891/891 [==============================] - 0s 383us/step - loss: 0.4169 - acc: 0.8272\n",
      "Epoch 67/100\n",
      "891/891 [==============================] - 0s 386us/step - loss: 0.4172 - acc: 0.8238\n",
      "Epoch 68/100\n",
      "891/891 [==============================] - 0s 270us/step - loss: 0.4168 - acc: 0.8316\n",
      "Epoch 69/100\n",
      "891/891 [==============================] - 0s 251us/step - loss: 0.4167 - acc: 0.8260\n",
      "Epoch 70/100\n",
      "891/891 [==============================] - 0s 243us/step - loss: 0.4160 - acc: 0.8283\n",
      "Epoch 71/100\n",
      "891/891 [==============================] - 0s 251us/step - loss: 0.4162 - acc: 0.8305\n",
      "Epoch 72/100\n",
      "891/891 [==============================] - 0s 290us/step - loss: 0.4158 - acc: 0.8283\n",
      "Epoch 73/100\n",
      "891/891 [==============================] - 0s 241us/step - loss: 0.4163 - acc: 0.8294\n",
      "Epoch 74/100\n",
      "891/891 [==============================] - 0s 255us/step - loss: 0.4154 - acc: 0.8350\n",
      "Epoch 75/100\n",
      "891/891 [==============================] - 0s 236us/step - loss: 0.4159 - acc: 0.8227\n",
      "Epoch 76/100\n",
      "891/891 [==============================] - 0s 273us/step - loss: 0.4153 - acc: 0.8294\n",
      "Epoch 77/100\n",
      "891/891 [==============================] - 0s 263us/step - loss: 0.4151 - acc: 0.8294\n",
      "Epoch 78/100\n",
      "891/891 [==============================] - 0s 327us/step - loss: 0.4148 - acc: 0.8272\n",
      "Epoch 79/100\n",
      "891/891 [==============================] - 0s 341us/step - loss: 0.4151 - acc: 0.8305\n",
      "Epoch 80/100\n",
      "891/891 [==============================] - 0s 460us/step - loss: 0.4162 - acc: 0.8294\n",
      "Epoch 81/100\n",
      "891/891 [==============================] - 0s 370us/step - loss: 0.4150 - acc: 0.8238\n",
      "Epoch 82/100\n",
      "891/891 [==============================] - 0s 467us/step - loss: 0.4146 - acc: 0.8272\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "891/891 [==============================] - 0s 474us/step - loss: 0.4145 - acc: 0.8339\n",
      "Epoch 84/100\n",
      "891/891 [==============================] - 0s 427us/step - loss: 0.4146 - acc: 0.8272\n",
      "Epoch 85/100\n",
      "891/891 [==============================] - 0s 451us/step - loss: 0.4152 - acc: 0.8294\n",
      "Epoch 86/100\n",
      "891/891 [==============================] - 0s 383us/step - loss: 0.4147 - acc: 0.8339\n",
      "Epoch 87/100\n",
      "891/891 [==============================] - 0s 499us/step - loss: 0.4142 - acc: 0.8294\n",
      "Epoch 88/100\n",
      "891/891 [==============================] - 0s 418us/step - loss: 0.4142 - acc: 0.8272\n",
      "Epoch 89/100\n",
      "891/891 [==============================] - 0s 405us/step - loss: 0.4143 - acc: 0.8272\n",
      "Epoch 90/100\n",
      "891/891 [==============================] - 0s 376us/step - loss: 0.4142 - acc: 0.8272\n",
      "Epoch 91/100\n",
      "891/891 [==============================] - 0s 393us/step - loss: 0.4140 - acc: 0.8294\n",
      "Epoch 92/100\n",
      "891/891 [==============================] - 0s 278us/step - loss: 0.4138 - acc: 0.8384\n",
      "Epoch 93/100\n",
      "891/891 [==============================] - 0s 325us/step - loss: 0.4155 - acc: 0.8272\n",
      "Epoch 94/100\n",
      "891/891 [==============================] - 0s 308us/step - loss: 0.4139 - acc: 0.8260\n",
      "Epoch 95/100\n",
      "891/891 [==============================] - 0s 289us/step - loss: 0.4135 - acc: 0.8260\n",
      "Epoch 96/100\n",
      "891/891 [==============================] - 0s 313us/step - loss: 0.4139 - acc: 0.8316\n",
      "Epoch 97/100\n",
      "891/891 [==============================] - 0s 276us/step - loss: 0.4136 - acc: 0.8328\n",
      "Epoch 98/100\n",
      "891/891 [==============================] - 0s 258us/step - loss: 0.4133 - acc: 0.8328\n",
      "Epoch 99/100\n",
      "891/891 [==============================] - 0s 283us/step - loss: 0.4132 - acc: 0.8328\n",
      "Epoch 100/100\n",
      "891/891 [==============================] - 0s 264us/step - loss: 0.4142 - acc: 0.8305\n"
     ]
    }
   ],
   "source": [
    "\n",
    "classifier = Sequential()\n",
    "\n",
    "#Input layer with 5 inputs neurons\n",
    "classifier.add(Dense(output_dim = 3, init = 'uniform', activation = 'relu', input_dim = 8))\n",
    "#Hidden layer\n",
    "classifier.add(Dense(output_dim = 2, init = 'uniform', activation = 'relu'))\n",
    "#output layer with 1 output neuron which will predict 1 or 0\n",
    "classifier.add(Dense(output_dim = 1, init = 'uniform', activation = 'sigmoid'))\n",
    "\n",
    "\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "classifier.fit(X_train, y_train, batch_size = 10, nb_epoch = 100)\n",
    "\n",
    "prediction = classifier.predict(X_test).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     PassengerId  Survived\n",
      "0            892         0\n",
      "1            893         0\n",
      "2            894         0\n",
      "3            895         0\n",
      "4            896         0\n",
      "5            897         0\n",
      "6            898         1\n",
      "7            899         0\n",
      "8            900         1\n",
      "9            901         0\n",
      "10           902         0\n",
      "11           903         0\n",
      "12           904         1\n",
      "13           905         0\n",
      "14           906         1\n",
      "15           907         1\n",
      "16           908         0\n",
      "17           909         0\n",
      "18           910         0\n",
      "19           911         1\n",
      "20           912         0\n",
      "21           913         0\n",
      "22           914         1\n",
      "23           915         0\n",
      "24           916         1\n",
      "25           917         0\n",
      "26           918         1\n",
      "27           919         0\n",
      "28           920         0\n",
      "29           921         0\n",
      "..           ...       ...\n",
      "388         1280         0\n",
      "389         1281         0\n",
      "390         1282         1\n",
      "391         1283         1\n",
      "392         1284         0\n",
      "393         1285         0\n",
      "394         1286         0\n",
      "395         1287         1\n",
      "396         1288         0\n",
      "397         1289         1\n",
      "398         1290         0\n",
      "399         1291         0\n",
      "400         1292         1\n",
      "401         1293         0\n",
      "402         1294         1\n",
      "403         1295         0\n",
      "404         1296         0\n",
      "405         1297         0\n",
      "406         1298         0\n",
      "407         1299         0\n",
      "408         1300         1\n",
      "409         1301         0\n",
      "410         1302         1\n",
      "411         1303         1\n",
      "412         1304         0\n",
      "413         1305         0\n",
      "414         1306         1\n",
      "415         1307         0\n",
      "416         1308         0\n",
      "417         1309         0\n",
      "\n",
      "[418 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "se = pd.Series(prediction)\n",
    "test_data['prediction'] = se\n",
    "test_data['prediction'] = test_data['prediction'].str.get(0)\n",
    "\n",
    "\n",
    "series = []\n",
    "for val in test_data.prediction:\n",
    "    if val >= 0.5:\n",
    "        series.append(1)\n",
    "    else:\n",
    "        series.append(0)\n",
    "\n",
    "test_data1['Survived'] = series\n",
    "test_data1 = test_data1[['PassengerId','Survived']]\n",
    "#test_data1.to_csv('output.csv')\n",
    "print(test_data1)\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "    print(test_data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
